{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins import projector\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "import recon\n",
    "import encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(31415926)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = recon.clean(pd.concat([recon.load('data/middle_chinese.csv'), recon.load('data/xiangyu.csv')], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "initials = [c for c in data.columns if c.endswith('聲母')]\n",
    "finals = [c for c in data.columns if c.endswith('韻母')]\n",
    "tones = [c for c in data.columns if c.endswith('調值')]\n",
    "columns = initials + finals + tones\n",
    "\n",
    "data.dropna(how='all', subset=columns, inplace=True)\n",
    "for c in columns:\n",
    "    data[c] = data[c].astype('category')\n",
    "\n",
    "categories = [data[c].cat.categories for c in columns]\n",
    "limits = np.cumsum([0] + [len(c) for c in categories])\n",
    "bases = limits[:-1]\n",
    "\n",
    "codes = np.empty(data[columns].shape, dtype=np.int32)\n",
    "for i, c in enumerate(columns):\n",
    "    codes[:, i] = data[c].cat.codes\n",
    "\n",
    "codes = pd.DataFrame(columns=columns, data=np.where(codes >= 0, codes + bases, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_categories = [t.categories for t in data.dtypes[initials]]\n",
    "final_categories = [t.categories for t in data.dtypes[finals]]\n",
    "tone_categories = [t.categories for t in data.dtypes[tones]]\n",
    "categories = initial_categories + final_categories + tone_categories\n",
    "\n",
    "generator = encoder.NoiseGenerator(codes[initials].values, codes[finals].values, codes[tones].values)\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    generator.noise(0.5),\n",
    "    output_types=((tf.int32, tf.int32, tf.int32), tf.int32)\n",
    ").shuffle(1000).padded_batch(100, padded_shapes=(((None,), (None,), (None,)), (None,)), padding_values=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(codes.values).shuffle(1000).batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 10\n",
    "encoder = encoder.DenoisingAutoEncoder([len(c) for c in categories], emb_size)\n",
    "optimizer = tf.optimizers.Adam()\n",
    "\n",
    "output_prefix = '/home/yihuahuang/notebook/tensorboard/sinetym/{}'.format(\n",
    "    datetime.datetime.now().strftime('%Y%m%d%H%M')\n",
    ")\n",
    "\n",
    "log_dir = output_prefix\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "loss = tf.keras.metrics.Mean('loss', dtype=tf.float32)\n",
    "acc = tf.keras.metrics.Accuracy('acc', dtype=tf.float32)\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(embedding=encoder.embedding, optimizer=optimizer)\n",
    "manager = tf.train.CheckpointManager(checkpoint, '{}/checkpoints'.format(output_prefix), max_to_keep=10)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for targets in dataset:\n",
    "        inputs = tf.where(tf.random.uniform(targets.shape) < 0.5, targets, tf.cast(tf.fill(targets.shape, -1), targets.dtype))\n",
    "        inputs = tf.reshape(inputs, (inputs.shape[0], 3, -1))\n",
    "        loss(encoder.update(inputs, targets, optimizer))\n",
    "        acc.update_state(targets, encoder.predict(inputs), tf.cast(targets >= 0, tf.float32))\n",
    "\n",
    "    with summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', loss.result(), step=epoch)\n",
    "            tf.summary.scalar('acc', acc.result(), step=epoch)\n",
    "    loss.reset_states()\n",
    "    acc.reset_states()\n",
    "\n",
    "    manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_emb = encoder.encode(codes[initials].values).numpy()\n",
    "final_emb = encoder.encode(codes[finals].values).numpy()\n",
    "tone_emb = encoder.encode(codes[tones].values).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'mathtext.fontset': 'dejavusans',\n",
    "    'font.serif': ['AR PL UMing CN'],\n",
    "    'axes.unicode_minus': False,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(2)\n",
    "\n",
    "pc = pca.fit_transform(initial_emb)\n",
    "emb_pc = pca.transform(encoder.embedding.numpy())\n",
    "out_emb_pc = pca.transform(encoder.output_embedding.numpy())\n",
    "\n",
    "plt.rcParams['font.size'] = 14\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "plt.scatter(pc[:, 0], pc[:, 1], color='gray', alpha=0.1)\n",
    "\n",
    "for i, col in enumerate(initials):\n",
    "    plt.scatter(emb_pc[limits[i]:limits[i + 1], 0], emb_pc[limits[i]:limits[i + 1], 1], label=col)\n",
    "    for j, c in enumerate(initial_categories[i]):\n",
    "        plt.annotate(r'$\\mathrm{{{}}}$'.format(c), xy=(emb_pc[bases[i] + j, 0], emb_pc[bases[i] + j, 1]))\n",
    "        \n",
    "    continue\n",
    "    plt.scatter(out_emb_pc[limits[i]:limits[i + 1], 0], out_emb_pc[limits[i]:limits[i + 1], 1], marker='^', label=col)\n",
    "    for j, c in enumerate(initial_categories[i]):\n",
    "        plt.annotate(r'$\\mathrm{{{}}}$'.format(c), xy=(out_emb_pc[bases[i] + j, 0], out_emb_pc[bases[i] + j, 1]))\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 15))\n",
    "axes = (ax1, ax2, ax3, ax4)\n",
    "\n",
    "for i in range(4):\n",
    "    checkpoint.restore('/home/yihuahuang/notebook/tensorboard/sinetym/202102241849/checkpoints/ckpt-{}'.format(i + 1))\n",
    "    \n",
    "    initial_emb = encoder.encode(codes[initials].values).numpy()\n",
    "\n",
    "    pca = PCA(2)\n",
    "    pc = pca.fit_transform(tf.linalg.normalize(initial_emb, axis=1)[0].numpy())\n",
    "    emb_pc = pca.transform(tf.linalg.normalize(encoder.embedding, axis=1)[0].numpy())\n",
    "    out_emb_pc = pca.transform(tf.linalg.normalize(encoder.output_embedding, axis=1)[0].numpy())\n",
    "\n",
    "    axes[i].scatter(pc[:, 0], pc[:, 1], color='gray', alpha=0.1)\n",
    "\n",
    "    for j, col in enumerate(initials):\n",
    "        axes[i].scatter(emb_pc[limits[j]:limits[j + 1], 0], emb_pc[limits[j]:limits[j + 1], 1], label=col)\n",
    "        axes[i].scatter(out_emb_pc[limits[j]:limits[j + 1], 0], out_emb_pc[limits[j]:limits[j + 1], 1], marker='^', label=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_tsne = TSNE(2).fit_transform(encoder.embedding.numpy())\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "for i, cols in enumerate((initials, finals, tones)):\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "    for j, col in enumerate(cols):\n",
    "        plt.scatter(emb_tsne[limits[i * 4 + j]:limits[i * 4 + j + 1], 0], emb_tsne[limits[i * 4 + j]:limits[i * 4 + j + 1], 1], label=col)\n",
    "        for k, c in enumerate(data[col].cat.categories):\n",
    "            plt.annotate(r'$\\mathrm{{{}}}$'.format(c), xy=(emb_tsne[bases[i * 4 + j] + k, 0], emb_tsne[bases[i * 4 + j] + k, 1]))\n",
    "    \n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "for cols, emb in ((initials, initial_emb), (finals, final_emb), (tones, tone_emb)):\n",
    "    pc = PCA(2).fit_transform(emb)\n",
    "\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 15))\n",
    "    axes = (ax1, ax2, ax3, ax4)\n",
    "\n",
    "    for i, col in enumerate(cols):\n",
    "        axes[i].set_title(col)\n",
    "        for c in data[col].cat.categories:\n",
    "            points = pc[data[col] == c]\n",
    "            axes[i].scatter(points[:, 0], points[:, 1], alpha=0.1)\n",
    "            axes[i].annotate(r'$\\mathrm{{{}}}$'.format(c), xy=(np.mean(points, axis=0)[0], np.mean(points, axis=0)[1]))\n",
    "            \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "col = 1\n",
    "\n",
    "pc = PCA(2).fit_transform(encoder.embedding.numpy()[limits[col]:limits[col + 1]])\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.scatter(pc[:, 0], pc[:, 1])\n",
    "\n",
    "for i, c in enumerate(categories[col]):\n",
    "    plt.annotate(r'$\\mathrm{{{}}}$'.format(c), xy=(pc[i, 0], pc[i, 1]))\n",
    "    \n",
    "dic = dict((c, i) for i, c in enumerate(categories[col]))\n",
    "for group in (\n",
    "    ('p', 'pʰ'),\n",
    "    ('t', 'tʰ'),\n",
    "    ('k', 'kʰ'),\n",
    "    ('ts', 'tsʰ'),\n",
    "    ('tʂ', 'tʂʰ'),\n",
    "    ('tɕ', 'tɕʰ')\n",
    "):\n",
    "    idx = np.asarray([dic[c] for c in group])\n",
    "    plt.annotate('', xytext=(pc[dic[group[0]], 0], pc[dic[group[0]], 1]), xy=(pc[dic[group[1]], 0], pc[dic[group[1]], 1]), arrowprops={'arrowstyle': '->'})\n",
    "    \n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.scatter(pc[:, 0], pc[:, 1])\n",
    "\n",
    "for i, c in enumerate(categories[col]):\n",
    "    plt.annotate(r'$\\mathrm{{{}}}$'.format(c), xy=(pc[i, 0], pc[i, 1]))\n",
    "    \n",
    "fig.show()\n",
    "    \n",
    "dic = dict((c, i) for i, c in enumerate(categories[col]))\n",
    "for group in (\n",
    "    ('p', 'b'),\n",
    "    ('t', 'd'),\n",
    "    ('k', 'g'),\n",
    "    ('ts', 'dz'),\n",
    "    ('tʂ', 'dʐ'),\n",
    "    ('tɕ', 'dʑ')\n",
    "):\n",
    "    idx = np.asarray([dic[c] for c in group])\n",
    "    plt.annotate('', xytext=(pc[dic[group[0]], 0], pc[dic[group[0]], 1]), xy=(pc[dic[group[1]], 0], pc[dic[group[1]], 1]), arrowprops={'arrowstyle': '->'})\n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data['字形'].isin(('東', '通', '同', '龍'))\n",
    "\n",
    "embs = np.stack(\n",
    "    [np.zeros_like(initial_emb[mask]), initial_emb[mask], final_emb[mask], tone_emb[mask]],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "points = np.cumsum(embs, axis=1)\n",
    "\n",
    "pca = PCA(2)\n",
    "pca.fit(np.reshape(embs, (-1, embs.shape[-1])))\n",
    "\n",
    "plt.rcParams['font.size'] = 14\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(embs.shape[0]):\n",
    "    pc = pca.transform(np.cumsum(embs[i], axis=0))\n",
    "    plt.scatter(pc[:, 0], pc[:, 1], label=data[mask]['字形'].iloc[i])\n",
    "    for j in range(pc.shape[0] - 1):\n",
    "        plt.annotate('', xytext=(pc[j, 0], pc[j, 1]), xy=(pc[j + 1, 0], pc[j + 1, 1]), arrowprops={'arrowstyle': '->'})\n",
    "    \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "for cols, emb, clusters in ((initials, initial_emb, 30), (finals, final_emb, 50), (tones, tone_emb, 10)):\n",
    "    pca = PCA(2)\n",
    "    pc = pca.fit_transform(emb)\n",
    "    km = KMeans(n_clusters=clusters)\n",
    "    km.fit(emb)\n",
    "    center_pc = pca.transform(km.cluster_centers_)\n",
    "\n",
    "    fit = plt.figure(figsize=(15, 15))\n",
    "    for i in range(km.cluster_centers_.shape[0]):\n",
    "        labels = data[km.labels_ == i][cols].mode().iloc[0]\n",
    "        labels = labels[labels.notna()]\n",
    "        if len(set(labels)) == 1:\n",
    "            label = labels.iloc[0]\n",
    "        else:\n",
    "            label = '-'.join(labels)\n",
    "        plt.scatter(pc[km.labels_ == i, 0], pc[km.labels_ == i, 1], alpha=0.1)\n",
    "        plt.annotate(r'$\\mathrm{{{}}}$'.format(label), xy=(center_pc[i, 0], center_pc[i, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "for columns, emb, clusters in ((initials, initial_emb, 30), (finals, final_emb, 50), (tones, tone_emb, 10)):\n",
    "    pca = PCA(2)\n",
    "    pc = pca.fit_transform(emb)\n",
    "    ac = AgglomerativeClustering(n_clusters=clusters)\n",
    "    ac.fit(emb)\n",
    "\n",
    "    fit = plt.figure(figsize=(15, 15))\n",
    "    for i in range(ac.n_clusters_):\n",
    "        labels = data[ac.labels_ == i][columns].mode().iloc[0]\n",
    "        labels = labels[labels.notna()]\n",
    "        if len(set(labels)) == 1:\n",
    "            label = labels.iloc[0]\n",
    "        else:\n",
    "            label = '-'.join(labels)\n",
    "        plt.scatter(pc[ac.labels_ == i, 0], pc[ac.labels_ == i, 1], alpha=0.1)\n",
    "        plt.annotate(r'$\\mathrm{{{}}}$'.format(label), xy=(np.mean(pc[ac.labels_ == i], axis=0)[0], np.mean(pc[ac.labels_ == i], axis=0)[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
